/**
 * TTS ìŒì„± ìƒì„± ìŠ¤í¬ë¦½íŠ¸
 *
 * ì‚¬ìš©ë²•:
 *   node scripts/generate-tts.mjs              # OpenAI ì‚¬ìš© (ê¸°ë³¸ê°’)
 *   node scripts/generate-tts.mjs --openai     # OpenAI ì‚¬ìš©
 *   node scripts/generate-tts.mjs --elevenlabs # ElevenLabs ì‚¬ìš©
 */

import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import dotenv from "dotenv";

// ê²½ë¡œ ì„¤ì •
const __dirname = path.dirname(fileURLToPath(import.meta.url));
const projectRoot = path.join(__dirname, "..");
dotenv.config({ path: path.join(projectRoot, ".env") });

// CLI ì¸ì íŒŒì‹±
const args = process.argv.slice(2);
const useElevenLabs = args.includes("--elevenlabs") || args.includes("-e");
const provider = useElevenLabs ? "elevenlabs" : "openai";

// ë‚˜ë ˆì´ì…˜ íŒŒì¼ ê²½ë¡œ (--file ì˜µì…˜ìœ¼ë¡œ ì§€ì • ê°€ëŠ¥)
const fileArgIndex = args.findIndex(arg => arg === "--file" || arg === "-f");
const narrationFile = fileArgIndex !== -1 && args[fileArgIndex + 1]
  ? args[fileArgIndex + 1]
  : "narration.json";
const narrationPath = path.join(__dirname, narrationFile);

if (!fs.existsSync(narrationPath)) {
  console.error(`âŒ ë‚˜ë ˆì´ì…˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${narrationPath}`);
  process.exit(1);
}

const narration = JSON.parse(fs.readFileSync(narrationPath, "utf-8"));
console.log(`ğŸ“„ ë‚˜ë ˆì´ì…˜ íŒŒì¼: ${narrationFile}\n`);

// ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
const outputDir = path.join(projectRoot, "public", "audio");
if (!fs.existsSync(outputDir)) {
  fs.mkdirSync(outputDir, { recursive: true });
}

// ============================================
// OpenAI TTS
// ============================================
async function generateWithOpenAI(text, outputPath) {
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey || apiKey.includes("ì—¬ê¸°ì—")) {
    throw new Error("OPENAI_API_KEYê°€ .envì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
  }

  const response = await fetch("https://api.openai.com/v1/audio/speech", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${apiKey}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model: narration.openai?.model || "tts-1-hd",
      input: text,
      voice: narration.openai?.voice || "nova",
      response_format: "mp3",
    }),
  });

  if (!response.ok) {
    const error = await response.json();
    throw new Error(`OpenAI API ì˜¤ë¥˜: ${JSON.stringify(error)}`);
  }

  const buffer = await response.arrayBuffer();
  fs.writeFileSync(outputPath, Buffer.from(buffer));
}

// ============================================
// ElevenLabs TTS
// ============================================
async function generateWithElevenLabs(text, outputPath) {
  const apiKey = process.env.ELEVENLABS_API_KEY;
  if (!apiKey || apiKey.includes("ì—¬ê¸°ì—")) {
    throw new Error("ELEVENLABS_API_KEYê°€ .envì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
  }

  // ElevenLabs ìŒì„± ID (ê¸°ë³¸ê°’: Rachel - í•œêµ­ì–´ ì§€ì› ìŒì„±)
  const voiceId = narration.elevenlabs?.voiceId || "21m00Tcm4TlvDq8ikWAM";
  const modelId = narration.elevenlabs?.modelId || "eleven_multilingual_v2";

  const response = await fetch(
    `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`,
    {
      method: "POST",
      headers: {
        "xi-api-key": apiKey,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        text: text,
        model_id: modelId,
        voice_settings: {
          stability: narration.elevenlabs?.stability || 0.5,
          similarity_boost: narration.elevenlabs?.similarityBoost || 0.75,
        },
      }),
    }
  );

  if (!response.ok) {
    const error = await response.text();
    throw new Error(`ElevenLabs API ì˜¤ë¥˜: ${error}`);
  }

  const buffer = await response.arrayBuffer();
  fs.writeFileSync(outputPath, Buffer.from(buffer));
}

// ============================================
// ë©”ì¸ ì‹¤í–‰
// ============================================
async function main() {
  const providerName = provider === "elevenlabs" ? "ElevenLabs" : "OpenAI";
  const generateFn =
    provider === "elevenlabs" ? generateWithElevenLabs : generateWithOpenAI;

  console.log(`ğŸ™ï¸  ${providerName} TTS ìŒì„± ìƒì„± ì‹œì‘\n`);
  console.log(`Provider: ${providerName}`);
  console.log(`ì”¬ ê°œìˆ˜: ${narration.scenes.length}\n`);

  for (const scene of narration.scenes) {
    const outputPath = path.join(outputDir, `${scene.id}.mp3`);

    console.log(`â³ [${scene.id}] ìƒì„± ì¤‘...`);
    console.log(`   "${scene.text.substring(0, 40)}..."`);

    try {
      await generateFn(scene.text, outputPath);
      console.log(`âœ… [${scene.id}] ì™„ë£Œ â†’ ${outputPath}\n`);
    } catch (error) {
      console.error(`âŒ [${scene.id}] ì‹¤íŒ¨: ${error.message}\n`);
    }
  }

  console.log("ğŸ‰ ëª¨ë“  ìŒì„± ìƒì„± ì™„ë£Œ!");
  console.log(`ğŸ“ ì¶œë ¥ ìœ„ì¹˜: ${outputDir}`);
}

main().catch(console.error);
