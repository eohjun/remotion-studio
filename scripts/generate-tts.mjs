/**
 * TTS ìŒì„± ìƒì„± ìŠ¤í¬ë¦½íŠ¸
 *
 * ì‚¬ìš©ë²•:
 *   node scripts/generate-tts.mjs              # OpenAI ì‚¬ìš© (ê¸°ë³¸ê°’)
 *   node scripts/generate-tts.mjs --openai     # OpenAI ì‚¬ìš©
 *   node scripts/generate-tts.mjs --elevenlabs # ElevenLabs ì‚¬ìš©
 *   node scripts/generate-tts.mjs --lang en    # ì˜ì–´ ìŒì„± ìƒì„±
 *   node scripts/generate-tts.mjs --translate --lang en # ë²ˆì—­ í›„ ì˜ì–´ ìŒì„± ìƒì„±
 *
 * ì¶œë ¥:
 *   - ê° ì”¬ë³„ MP3 íŒŒì¼
 *   - audio-metadata.json (ì˜¤ë””ì˜¤ ê¸¸ì´ ì •ë³´ í¬í•¨)
 */

import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import { execSync } from "child_process";
import dotenv from "dotenv";

// ê²½ë¡œ ì„¤ì •
const __dirname = path.dirname(fileURLToPath(import.meta.url));
const projectRoot = path.join(__dirname, "..");
dotenv.config({ path: path.join(projectRoot, ".env") });

// ì§€ì› ì–¸ì–´
const SUPPORTED_LANGUAGES = ["ko", "en", "ja", "zh"];
const LANGUAGE_NAMES = {
  ko: "í•œêµ­ì–´",
  en: "English",
  ja: "æ—¥æœ¬èª",
  zh: "ä¸­æ–‡",
};

// ì–¸ì–´ë³„ ê¸°ë³¸ ìŒì„± ì„¤ì •
const VOICE_CONFIGS = {
  ko: { openai: "nova", elevenlabs: "pNInz6obpgDQGcFmaJgB", model: "eleven_multilingual_v2" },
  en: { openai: "alloy", elevenlabs: "21m00Tcm4TlvDq8ikWAM", model: "eleven_monolingual_v1" },
  ja: { openai: "nova", elevenlabs: "pNInz6obpgDQGcFmaJgB", model: "eleven_multilingual_v2" },
  zh: { openai: "nova", elevenlabs: "pNInz6obpgDQGcFmaJgB", model: "eleven_multilingual_v2" },
};

// CLI ì¸ì íŒŒì‹±
const args = process.argv.slice(2);
const useElevenLabs = args.includes("--elevenlabs") || args.includes("-e");
const provider = useElevenLabs ? "elevenlabs" : "openai";
const doTranslate = args.includes("--translate") || args.includes("-t");

// ì–¸ì–´ ì„¤ì •
const langArgIndex = args.findIndex(arg => arg === "--lang" || arg === "-l");
const targetLang = langArgIndex !== -1 && args[langArgIndex + 1]
  ? args[langArgIndex + 1]
  : "ko";

if (!SUPPORTED_LANGUAGES.includes(targetLang)) {
  console.error(`âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” ì–¸ì–´: ${targetLang}`);
  console.error(`   ì§€ì› ì–¸ì–´: ${SUPPORTED_LANGUAGES.join(", ")}`);
  process.exit(1);
}

// ë‚˜ë ˆì´ì…˜ íŒŒì¼ ê²½ë¡œ (--file ì˜µì…˜ìœ¼ë¡œ ì§€ì • ê°€ëŠ¥)
const fileArgIndex = args.findIndex(arg => arg === "--file" || arg === "-f");
const narrationFile = fileArgIndex !== -1 && args[fileArgIndex + 1]
  ? args[fileArgIndex + 1]
  : "narration.json";
const narrationPath = path.join(__dirname, narrationFile);

if (!fs.existsSync(narrationPath)) {
  console.error(`âŒ ë‚˜ë ˆì´ì…˜ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${narrationPath}`);
  process.exit(1);
}

const narration = JSON.parse(fs.readFileSync(narrationPath, "utf-8"));
console.log(`ğŸ“„ ë‚˜ë ˆì´ì…˜ íŒŒì¼: ${narrationFile}`);
console.log(`ğŸŒ ëŒ€ìƒ ì–¸ì–´: ${LANGUAGE_NAMES[targetLang]} (${targetLang})\n`);

// ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²°ì • (ìš°ì„ ìˆœìœ„: --output > metadata.compositionId > ì–¸ì–´ë³„ í´ë”)
const outputArgIndex = args.findIndex(arg => arg === "--output" || arg === "-o");
const customOutputDir = outputArgIndex !== -1 && args[outputArgIndex + 1]
  ? args[outputArgIndex + 1]
  : null;

// compositionId ê¸°ë°˜ ì¶œë ¥ (ê¶Œì¥)
const compositionId = narration.metadata?.compositionId;

let outputDir;
if (customOutputDir) {
  // ëª…ì‹œì  --output ì˜µì…˜ ì‚¬ìš©
  outputDir = path.join(projectRoot, "public", "videos", customOutputDir, "audio");
} else if (compositionId) {
  // metadata.compositionId ì‚¬ìš© (ê¶Œì¥)
  outputDir = path.join(projectRoot, "public", "videos", compositionId, "audio");
  console.log(`ğŸ“ compositionId ê¸°ë°˜ ì¶œë ¥: public/videos/${compositionId}/audio/`);
} else {
  // í´ë°±: compositionId í•„ìˆ˜
  console.error(`âŒ metadata.compositionIdê°€ ì—†ìŠµë‹ˆë‹¤.`);
  console.error(`   narration.jsonì— "metadata": { "compositionId": "YourVideoName" } ì¶”ê°€ í•„ìš”`);
  process.exit(1);
}

if (!fs.existsSync(outputDir)) {
  fs.mkdirSync(outputDir, { recursive: true });
}

// ============================================
// ì–¸ì–´ ê°ì§€
// ============================================
function detectLanguage(text) {
  const koPattern = /[\uAC00-\uD7AF]/g;
  const jaPattern = /[\u3040-\u309F\u30A0-\u30FF]/g;
  const zhPattern = /[\u4E00-\u9FFF]/g;

  const koCount = (text.match(koPattern) || []).length;
  const jaCount = (text.match(jaPattern) || []).length;
  const zhCount = (text.match(zhPattern) || []).length;

  if (koCount > 10) return "ko";
  if (jaCount > 10) return "ja";
  if (zhCount > 20 && jaCount < 5) return "zh";
  return "en";
}

// ============================================
// ë²ˆì—­ (OpenAI ì‚¬ìš©)
// ============================================
async function translateText(text, sourceLang, targetLang) {
  if (sourceLang === targetLang) return text;

  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) {
    throw new Error("ë²ˆì—­ì„ ìœ„í•´ OPENAI_API_KEYê°€ í•„ìš”í•©ë‹ˆë‹¤.");
  }

  const sourceName = LANGUAGE_NAMES[sourceLang] || sourceLang;
  const targetName = LANGUAGE_NAMES[targetLang] || targetLang;

  const response = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${apiKey}`,
    },
    body: JSON.stringify({
      model: "gpt-4o-mini",
      messages: [
        {
          role: "system",
          content: `You are a professional translator. Translate the following text from ${sourceName} to ${targetName}. Maintain the original tone and meaning. Only output the translation, nothing else.`,
        },
        { role: "user", content: text },
      ],
      temperature: 0.3,
    }),
  });

  if (!response.ok) {
    const error = await response.text();
    throw new Error(`ë²ˆì—­ API ì˜¤ë¥˜: ${error}`);
  }

  const data = await response.json();
  return data.choices[0]?.message?.content?.trim() || text;
}

// ============================================
// OpenAI TTS
// ============================================
async function generateWithOpenAI(text, outputPath, lang) {
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey || apiKey.includes("ì—¬ê¸°ì—")) {
    throw new Error("OPENAI_API_KEYê°€ .envì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
  }

  const voiceConfig = VOICE_CONFIGS[lang] || VOICE_CONFIGS.en;
  const voice = narration.openai?.voice || voiceConfig.openai;

  const response = await fetch("https://api.openai.com/v1/audio/speech", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${apiKey}`,
      "Content-Type": "application/json",
    },
    body: JSON.stringify({
      model: narration.openai?.model || "tts-1-hd",
      input: text,
      voice: voice,
      response_format: "mp3",
    }),
  });

  if (!response.ok) {
    const error = await response.json();
    throw new Error(`OpenAI API ì˜¤ë¥˜: ${JSON.stringify(error)}`);
  }

  const buffer = await response.arrayBuffer();
  fs.writeFileSync(outputPath, Buffer.from(buffer));
}

// ============================================
// ElevenLabs TTS
// ============================================
async function generateWithElevenLabs(text, outputPath, lang) {
  const apiKey = process.env.ELEVENLABS_API_KEY;
  if (!apiKey || apiKey.includes("ì—¬ê¸°ì—")) {
    throw new Error("ELEVENLABS_API_KEYê°€ .envì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
  }

  const voiceConfig = VOICE_CONFIGS[lang] || VOICE_CONFIGS.en;
  const voiceId = narration.elevenlabs?.voiceId || voiceConfig.elevenlabs;
  const modelId = narration.elevenlabs?.modelId || voiceConfig.model;

  const response = await fetch(
    `https://api.elevenlabs.io/v1/text-to-speech/${voiceId}`,
    {
      method: "POST",
      headers: {
        "xi-api-key": apiKey,
        "Content-Type": "application/json",
      },
      body: JSON.stringify({
        text: text,
        model_id: modelId,
        voice_settings: {
          stability: narration.elevenlabs?.stability || 0.5,
          similarity_boost: narration.elevenlabs?.similarityBoost || 0.75,
        },
      }),
    }
  );

  if (!response.ok) {
    const error = await response.text();
    throw new Error(`ElevenLabs API ì˜¤ë¥˜: ${error}`);
  }

  const buffer = await response.arrayBuffer();
  fs.writeFileSync(outputPath, Buffer.from(buffer));
}

// ============================================
// ì˜¤ë””ì˜¤ ê¸¸ì´ ì¸¡ì • (ffprobe ì‚¬ìš©)
// ============================================
function getAudioDuration(filePath) {
  try {
    const result = execSync(
      `ffprobe -i "${filePath}" -show_entries format=duration -v quiet -of csv="p=0"`,
      { encoding: "utf-8" }
    );
    return parseFloat(result.trim());
  } catch (error) {
    console.error(`âš ï¸ ì˜¤ë””ì˜¤ ê¸¸ì´ ì¸¡ì • ì‹¤íŒ¨: ${filePath}`);
    return null;
  }
}

// ============================================
// ë©”ì¸ ì‹¤í–‰
// ============================================
async function main() {
  const providerName = provider === "elevenlabs" ? "ElevenLabs" : "OpenAI";
  const generateFn =
    provider === "elevenlabs" ? generateWithElevenLabs : generateWithOpenAI;

  console.log(`ğŸ™ï¸  ${providerName} TTS ìŒì„± ìƒì„± ì‹œì‘`);
  console.log(`Provider: ${providerName}`);
  console.log(`ì”¬ ê°œìˆ˜: ${narration.scenes.length}`);
  if (doTranslate) {
    console.log(`ë²ˆì—­: í™œì„±í™” (â†’ ${LANGUAGE_NAMES[targetLang]})`);
  }
  console.log("");

  // ë²ˆì—­ëœ í…ìŠ¤íŠ¸ ì €ì¥ (ë‚˜ì¤‘ì— ì°¸ì¡°ìš©)
  const translatedScenes = [];
  // ì˜¤ë””ì˜¤ ë©”íƒ€ë°ì´í„° ì €ì¥
  const audioMetadata = {
    generatedAt: new Date().toISOString(),
    provider: providerName,
    language: targetLang,
    outputDir: outputDir,
    compositionId: narration.metadata?.compositionId || null,
    scenes: [],
  };

  for (const scene of narration.scenes) {
    const outputPath = path.join(outputDir, `${scene.id}.mp3`);
    let textToSpeak = scene.text;

    // ë²ˆì—­ ì²˜ë¦¬
    if (doTranslate) {
      const detectedLang = detectLanguage(scene.text);
      if (detectedLang !== targetLang) {
        console.log(`ğŸ”„ [${scene.id}] ë²ˆì—­ ì¤‘ (${detectedLang} â†’ ${targetLang})...`);
        try {
          textToSpeak = await translateText(scene.text, detectedLang, targetLang);
          translatedScenes.push({
            id: scene.id,
            original: scene.text,
            translated: textToSpeak,
          });
        } catch (error) {
          console.error(`   ë²ˆì—­ ì‹¤íŒ¨: ${error.message}`);
          // ë²ˆì—­ ì‹¤íŒ¨ ì‹œ ì›ë³¸ ì‚¬ìš©
        }
      }
    }

    console.log(`â³ [${scene.id}] ìƒì„± ì¤‘...`);
    console.log(`   "${textToSpeak.substring(0, 50)}..."`);

    try {
      await generateFn(textToSpeak, outputPath, targetLang);

      // ì˜¤ë””ì˜¤ ê¸¸ì´ ì¸¡ì •
      const durationSeconds = getAudioDuration(outputPath);
      const sceneMetadata = {
        id: scene.id,
        file: `${scene.id}.mp3`,
        durationSeconds: durationSeconds,
        durationFrames: durationSeconds ? Math.ceil(durationSeconds * 30) : null, // 30fps ê¸°ì¤€
        text: textToSpeak.substring(0, 100) + (textToSpeak.length > 100 ? "..." : ""),
      };
      audioMetadata.scenes.push(sceneMetadata);

      console.log(`âœ… [${scene.id}] ì™„ë£Œ (${durationSeconds?.toFixed(1)}s) â†’ ${outputPath}\n`);
    } catch (error) {
      console.error(`âŒ [${scene.id}] ì‹¤íŒ¨: ${error.message}\n`);
      audioMetadata.scenes.push({
        id: scene.id,
        file: `${scene.id}.mp3`,
        durationSeconds: null,
        durationFrames: null,
        error: error.message,
      });
    }
  }

  // ë²ˆì—­ëœ ë‚´ìš© ì €ì¥ (ì°¸ì¡°ìš©)
  if (doTranslate && translatedScenes.length > 0) {
    const translatedPath = path.join(__dirname, `narration_${targetLang}.json`);
    const translatedNarration = {
      ...narration,
      language: targetLang,
      originalLanguage: detectLanguage(narration.scenes[0]?.text || ""),
      scenes: narration.scenes.map(scene => {
        const translated = translatedScenes.find(t => t.id === scene.id);
        return {
          ...scene,
          text: translated ? translated.translated : scene.text,
          originalText: translated ? translated.original : undefined,
        };
      }),
    };
    fs.writeFileSync(translatedPath, JSON.stringify(translatedNarration, null, 2));
    console.log(`ğŸ“ ë²ˆì—­ëœ ë‚˜ë ˆì´ì…˜ ì €ì¥: ${translatedPath}`);
  }

  // ì˜¤ë””ì˜¤ ë©”íƒ€ë°ì´í„° ì €ì¥
  const metadataPath = path.join(outputDir, "audio-metadata.json");
  fs.writeFileSync(metadataPath, JSON.stringify(audioMetadata, null, 2));
  console.log(`\nğŸ“Š ì˜¤ë””ì˜¤ ë©”íƒ€ë°ì´í„° ì €ì¥: ${metadataPath}`);

  // ì´ ê¸¸ì´ ê³„ì‚°
  const totalSeconds = audioMetadata.scenes
    .filter(s => s.durationSeconds)
    .reduce((sum, s) => sum + s.durationSeconds, 0);
  const minutes = Math.floor(totalSeconds / 60);
  const seconds = Math.round(totalSeconds % 60);
  console.log(`â±ï¸  ì´ ì˜¤ë””ì˜¤ ê¸¸ì´: ${minutes}ë¶„ ${seconds}ì´ˆ`);

  console.log("\nğŸ‰ ëª¨ë“  ìŒì„± ìƒì„± ì™„ë£Œ!");
  console.log(`ğŸ“ ì¶œë ¥ ìœ„ì¹˜: ${outputDir}`);
  console.log(`\nğŸ’¡ Tip: 'node scripts/sync-durations.mjs ${metadataPath}' ë¡œ constants.ts ìë™ ìƒì„± ê°€ëŠ¥`);
}

main().catch(console.error);
