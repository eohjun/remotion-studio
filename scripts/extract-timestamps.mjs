/**
 * ì˜¤ë””ì˜¤ì—ì„œ ë¬¸ì¥ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ (OpenAI Whisper ì‚¬ìš©)
 *
 * ì‚¬ìš©ë²•:
 *   node scripts/extract-timestamps.mjs <compositionId>
 *   node scripts/extract-timestamps.mjs ZeigarnikEffect
 *   node scripts/extract-timestamps.mjs ZeigarnikEffect --scene hook
 *
 * ì¶œë ¥:
 *   - public/videos/{compositionId}/audio/timestamps.json
 *   - ê° ì”¬ë³„ ë¬¸ì¥/ë‹¨ì–´ íƒ€ì„ìŠ¤íƒ¬í”„
 *
 * âš ï¸ ìš”êµ¬ì‚¬í•­:
 *   - OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”
 *   - TTS ì˜¤ë””ì˜¤ê°€ ë¨¼ì € ìƒì„±ë˜ì–´ ìˆì–´ì•¼ í•¨
 */

import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import dotenv from "dotenv";

const __dirname = path.dirname(fileURLToPath(import.meta.url));
const projectRoot = path.join(__dirname, "..");
dotenv.config({ path: path.join(projectRoot, ".env") });

// CLI ì¸ì íŒŒì‹±
const args = process.argv.slice(2);

if (args.length === 0 || args.includes("--help") || args.includes("-h")) {
  console.log(`
ì‚¬ìš©ë²•: node scripts/extract-timestamps.mjs <compositionId> [ì˜µì…˜]

ì˜µì…˜:
  --scene, -s <id>    íŠ¹ì • ì”¬ë§Œ ì²˜ë¦¬ (ì˜ˆ: hook,discovery)
  --verbose, -v       ìƒì„¸ ì¶œë ¥

ì˜ˆì‹œ:
  node scripts/extract-timestamps.mjs ZeigarnikEffect
  node scripts/extract-timestamps.mjs ZeigarnikEffect --scene hook
`);
  process.exit(0);
}

const compositionId = args[0];
const sceneArgIndex = args.findIndex(arg => arg === "--scene" || arg === "-s");
const sceneFilter = sceneArgIndex !== -1 && args[sceneArgIndex + 1]
  ? args[sceneArgIndex + 1].split(",").map(s => s.trim())
  : null;
const verbose = args.includes("--verbose") || args.includes("-v");

// ê²½ë¡œ ì„¤ì •
const audioDir = path.join(projectRoot, "public", "videos", compositionId, "audio");
const metadataPath = path.join(audioDir, "audio-metadata.json");

if (!fs.existsSync(metadataPath)) {
  console.error(`âŒ audio-metadata.jsonì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: ${metadataPath}`);
  console.error(`   ë¨¼ì € TTSë¥¼ ìƒì„±í•˜ì„¸ìš”: node scripts/generate-tts.mjs -f ../projects/${compositionId}/narration.json`);
  process.exit(1);
}

const metadata = JSON.parse(fs.readFileSync(metadataPath, "utf-8"));

// ============================================
// FPS ì½ê¸° (constants.tsì—ì„œ)
// ============================================
function getFpsFromConstants(compositionId) {
  const DEFAULT_FPS = 60;
  const constantsPath = path.join(projectRoot, "src", "videos", compositionId, "constants.ts");

  if (!fs.existsSync(constantsPath)) {
    console.log(`âš ï¸ constants.ts ì—†ìŒ, ê¸°ë³¸ FPS ì‚¬ìš©: ${DEFAULT_FPS}`);
    return DEFAULT_FPS;
  }

  try {
    const content = fs.readFileSync(constantsPath, "utf-8");
    const match = content.match(/export\s+const\s+FPS\s*=\s*(\d+)/);
    if (match) {
      return parseInt(match[1], 10);
    }
  } catch (error) {
    console.error(`âš ï¸ constants.ts ì½ê¸° ì‹¤íŒ¨: ${error.message}`);
  }

  return DEFAULT_FPS;
}

const PROJECT_FPS = getFpsFromConstants(compositionId);
console.log(`ğŸ“„ ë©”íƒ€ë°ì´í„° ë¡œë“œ: ${compositionId}`);
console.log(`ğŸ“Š ì”¬ ê°œìˆ˜: ${metadata.scenes.length}`);
if (sceneFilter) {
  console.log(`ğŸ¯ ì„ íƒëœ ì”¬: ${sceneFilter.join(", ")}`);
}
console.log("");

// ============================================
// Whisper APIë¡œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ
// ============================================
async function extractTimestamps(audioPath, language = "ko") {
  const apiKey = process.env.OPENAI_API_KEY;
  if (!apiKey) {
    throw new Error("OPENAI_API_KEYê°€ .envì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.");
  }

  // íŒŒì¼ ì½ê¸°
  const audioBuffer = fs.readFileSync(audioPath);
  const fileName = path.basename(audioPath);

  // FormData ìƒì„± (Node.js 18+ native)
  const formData = new FormData();
  const blob = new Blob([audioBuffer], { type: "audio/mpeg" });
  formData.append("file", blob, fileName);
  formData.append("model", "whisper-1");
  formData.append("language", language);
  formData.append("response_format", "verbose_json");
  formData.append("timestamp_granularities[]", "word");
  formData.append("timestamp_granularities[]", "segment");

  const response = await fetch("https://api.openai.com/v1/audio/transcriptions", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${apiKey}`,
    },
    body: formData,
  });

  if (!response.ok) {
    const error = await response.text();
    throw new Error(`Whisper API ì˜¤ë¥˜: ${error}`);
  }

  return await response.json();
}

// ============================================
// ë©”ì¸ ì‹¤í–‰
// ============================================
async function main() {
  const timestamps = {
    compositionId,
    generatedAt: new Date().toISOString(),
    fps: PROJECT_FPS,
    scenes: [],
  };

  for (const scene of metadata.scenes) {
    if (sceneFilter && !sceneFilter.includes(scene.id)) {
      console.log(`â­ï¸  [${scene.id}] ìŠ¤í‚µ`);
      continue;
    }

    const audioPath = path.join(audioDir, scene.file);
    if (!fs.existsSync(audioPath)) {
      console.log(`âš ï¸  [${scene.id}] ì˜¤ë””ì˜¤ íŒŒì¼ ì—†ìŒ: ${scene.file}`);
      continue;
    }

    console.log(`â³ [${scene.id}] íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ ì¤‘...`);

    try {
      const result = await extractTimestamps(audioPath, metadata.language || "ko");

      const sceneTimestamps = {
        id: scene.id,
        duration: scene.durationSeconds,
        durationFrames: scene.durationFrames,
        text: result.text,
        segments: result.segments?.map(seg => ({
          text: seg.text.trim(),
          start: seg.start,
          end: seg.end,
          startFrame: Math.round(seg.start * 30),
          endFrame: Math.round(seg.end * 30),
        })) || [],
        words: result.words?.map(word => ({
          word: word.word,
          start: word.start,
          end: word.end,
          startFrame: Math.round(word.start * 30),
          endFrame: Math.round(word.end * 30),
        })) || [],
      };

      timestamps.scenes.push(sceneTimestamps);

      if (verbose) {
        console.log(`   ğŸ“ í…ìŠ¤íŠ¸: "${result.text.substring(0, 50)}..."`);
        console.log(`   ğŸ“Š ì„¸ê·¸ë¨¼íŠ¸: ${sceneTimestamps.segments.length}ê°œ`);
        console.log(`   ğŸ“Š ë‹¨ì–´: ${sceneTimestamps.words.length}ê°œ`);
      }

      console.log(`âœ… [${scene.id}] ì™„ë£Œ - ${sceneTimestamps.segments.length}ê°œ ì„¸ê·¸ë¨¼íŠ¸, ${sceneTimestamps.words.length}ê°œ ë‹¨ì–´\n`);

    } catch (error) {
      console.error(`âŒ [${scene.id}] ì‹¤íŒ¨: ${error.message}\n`);
      timestamps.scenes.push({
        id: scene.id,
        error: error.message,
      });
    }
  }

  // íƒ€ì„ìŠ¤íƒ¬í”„ ì €ì¥
  const timestampsPath = path.join(audioDir, "timestamps.json");
  fs.writeFileSync(timestampsPath, JSON.stringify(timestamps, null, 2));
  console.log(`ğŸ“Š íƒ€ì„ìŠ¤íƒ¬í”„ ì €ì¥: ${timestampsPath}`);

  // ìš”ì•½ ì¶œë ¥
  console.log("\nğŸ“Š ì¶”ì¶œ ì™„ë£Œ ìš”ì•½:");
  for (const scene of timestamps.scenes) {
    if (scene.error) {
      console.log(`   âŒ ${scene.id}: ì‹¤íŒ¨`);
    } else {
      console.log(`   âœ… ${scene.id}: ${scene.segments?.length || 0} ì„¸ê·¸ë¨¼íŠ¸, ${scene.words?.length || 0} ë‹¨ì–´`);
    }
  }

  console.log(`\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„: node scripts/generate-visual-panels.mjs ${compositionId}`);
}

main().catch(console.error);
